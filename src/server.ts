import express from 'express';
import { LlmManager } from './llm_rotation';
import { determineProvider } from './provider-detection';
import type {
    ChatCompletionRequest,
    ChatCompletionResponse,
    ModelsListResponse,
    HealthCheckResponse,
    ServerConfig,
    ApiKeys,
    Provider,
    Message
} from './types';
import { ApiError } from './types';

const app = express();
const port = process.env.PORT || 3000;

// Middleware –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON
app.use(express.json({ limit: '10mb' }));

// –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä LlmManager
const llmManager = new LlmManager();

// –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å OpenAI API
app.post('/v1/chat/completions', async (req, res) => {
    try {
        const requestBody: ChatCompletionRequest = req.body;
        const { messages, model, temperature, max_tokens, top_p } = requestBody;

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        if (!messages || !Array.isArray(messages)) {
            const error = ApiError.validation('messages field is required and must be an array', {
                messages: 'Field is required and must be an array'
            });
            return res.status(error.statusCode).json(error.toResponse());
        }

        if (!model) {
            const error = ApiError.validation('model field is required', {
                model: 'Field is required'
            });
            return res.status(error.statusCode).json(error.toResponse());
        }

        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–∏
        const provider = determineProvider(model);

        if (!provider) {
            const error = ApiError.modelNotFound(model);
            return res.status(error.statusCode).json(error.toResponse());
        }

        // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è LlmManager
        const settings = {
            provider: provider,
            model: model,
            apiKeys: getApiKeysFromEnv(),
            temperature: temperature || 0.7,
            maxTokens: max_tokens || 2048,
            topP: top_p || 0.9,
            siteUrl: req.headers['http-referer'] as string || 'http://localhost:3000',
            siteName: req.headers['x-title'] as string || 'LLM Rotation Server'
        };

        // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        const response = await llmManager.generateResponse(messages, settings);

        // –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI API
        const openaiResponse: ChatCompletionResponse = {
            id: `chatcmpl-${Date.now()}`,
            object: 'chat.completion',
            created: Math.floor(Date.now() / 1000),
            model: model,
            choices: [{
                index: 0,
                message: {
                    role: 'assistant',
                    content: response
                },
                finish_reason: 'stop'
            }],
            usage: {
                prompt_tokens: estimateTokens(messages),
                completion_tokens: estimateTokens([{ role: 'assistant', content: response }]),
                total_tokens: estimateTokens(messages) + estimateTokens([{ role: 'assistant', content: response }])
            }
        };

        return res.json(openaiResponse);

    } catch (error) {
        console.error('Error processing request:', error);

        // Handle ApiError instances
        if (error instanceof ApiError) {
            return res.status(error.statusCode).json(error.toResponse());
        }

        // Handle generic errors
        const apiError = new ApiError(
            (error as Error).message || 'Internal server error',
            'server_error',
            'internal_error',
            500
        );
        return res.status(apiError.statusCode).json(apiError.toResponse());
    }
});



// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è API –∫–ª—é—á–µ–π –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
function getApiKeysFromEnv(): ApiKeys {
    return {
        gemini: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY || '',
        openrouter: process.env.OPENROUTER_API_KEY || '',
        huggingface: process.env.HUGGINGFACE_API_KEY || process.env.HF_TOKEN || '',
        mistral: process.env.MISTRAL_API_KEY || '',
        cohere: process.env.COHERE_API_KEY || '',
        nvidia: process.env.NVIDIA_API_KEY || '',
        chutes: process.env.CHUTES_API_KEY || '',
        requesty: process.env.REQUESTY_API_KEY || ''
    };
}

// –ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
function estimateTokens(messages: Message[]): number {
    const text = messages.map(m => m.content).join(' ');
    return Math.ceil(text.length / 4); // –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: ~4 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ —Ç–æ–∫–µ–Ω
}

// –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–µ—Ä–∞
app.get('/health', (_req, res) => {
    const healthResponse: HealthCheckResponse = {
        status: 'ok',
        timestamp: new Date().toISOString(),
        uptime: process.uptime() * 1000, // Convert to milliseconds
        memory: {
            used: process.memoryUsage().heapUsed,
            total: process.memoryUsage().heapTotal,
            percentage: (process.memoryUsage().heapUsed / process.memoryUsage().heapTotal) * 100
        }
    };
    res.json(healthResponse);
});

// –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
app.get('/v1/models', (_req, res) => {
    const models = [];

    for (const [provider, providerModels] of Object.entries(LlmManager.modelConfigurations)) {
        for (const model of providerModels) {
            models.push({
                id: model.id,
                object: 'model' as const,
                created: Math.floor(Date.now() / 1000),
                owned_by: provider,
                permission: [],
                root: model.id,
                parent: null
            });
        }
    }

    const response: ModelsListResponse = {
        object: 'list',
        data: models
    };

    res.json(response);
});

// –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
app.listen(port, () => {
    console.log(`üöÄ LLM Rotation Server –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É ${port}`);
    console.log(`üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã:`);
    console.log(`   POST /v1/chat/completions - –û—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è —á–∞—Ç–∞`);
    console.log(`   GET  /v1/models - –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π`);
    console.log(`   GET  /health - –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–∞`);
    console.log(`\nüîë –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è API –∫–ª—é—á–µ–π:`);
    console.log(`   GEMINI_API_KEY, OPENROUTER_API_KEY, HUGGINGFACE_API_KEY, –∏ —Ç.–¥.`);
});

export default app;