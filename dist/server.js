"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const express_1 = __importDefault(require("express"));
const llm_rotation_1 = require("./llm_rotation");
const provider_detection_1 = require("./provider-detection");
const types_1 = require("./types");
const app = (0, express_1.default)();
const port = process.env.PORT || 3000;
// Middleware –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON
app.use(express_1.default.json({ limit: '10mb' }));
// –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä LlmManager
const llmManager = new llm_rotation_1.LlmManager();
// –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å OpenAI API
app.post('/v1/chat/completions', async (req, res) => {
    try {
        const requestBody = req.body;
        const { messages, model, temperature, max_tokens, top_p } = requestBody;
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        if (!messages || !Array.isArray(messages)) {
            const error = types_1.ApiError.validation('messages field is required and must be an array', {
                messages: 'Field is required and must be an array'
            });
            return res.status(error.statusCode).json(error.toResponse());
        }
        if (!model) {
            const error = types_1.ApiError.validation('model field is required', {
                model: 'Field is required'
            });
            return res.status(error.statusCode).json(error.toResponse());
        }
        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–∏
        const provider = (0, provider_detection_1.determineProvider)(model);
        if (!provider) {
            const error = types_1.ApiError.modelNotFound(model);
            return res.status(error.statusCode).json(error.toResponse());
        }
        // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è LlmManager
        const settings = {
            provider: provider,
            model: model,
            apiKeys: getApiKeysFromEnv(),
            temperature: temperature || 0.7,
            maxTokens: max_tokens || 2048,
            topP: top_p || 0.9,
            siteUrl: req.headers['http-referer'] || 'http://localhost:3000',
            siteName: req.headers['x-title'] || 'LLM Rotation Server'
        };
        // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        const response = await llmManager.generateResponse(messages, settings);
        // –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI API
        const openaiResponse = {
            id: `chatcmpl-${Date.now()}`,
            object: 'chat.completion',
            created: Math.floor(Date.now() / 1000),
            model: model,
            choices: [{
                    index: 0,
                    message: {
                        role: 'assistant',
                        content: response
                    },
                    finish_reason: 'stop'
                }],
            usage: {
                prompt_tokens: estimateTokens(messages),
                completion_tokens: estimateTokens([{ role: 'assistant', content: response }]),
                total_tokens: estimateTokens(messages) + estimateTokens([{ role: 'assistant', content: response }])
            }
        };
        return res.json(openaiResponse);
    }
    catch (error) {
        console.error('Error processing request:', error);
        // Handle ApiError instances
        if (error instanceof types_1.ApiError) {
            return res.status(error.statusCode).json(error.toResponse());
        }
        // Handle generic errors
        const apiError = new types_1.ApiError(error.message || 'Internal server error', 'server_error', 'internal_error', 500);
        return res.status(apiError.statusCode).json(apiError.toResponse());
    }
});
// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è API –∫–ª—é—á–µ–π –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
function getApiKeysFromEnv() {
    return {
        gemini: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY || '',
        openrouter: process.env.OPENROUTER_API_KEY || '',
        huggingface: process.env.HUGGINGFACE_API_KEY || process.env.HF_TOKEN || '',
        mistral: process.env.MISTRAL_API_KEY || '',
        cohere: process.env.COHERE_API_KEY || '',
        nvidia: process.env.NVIDIA_API_KEY || '',
        chutes: process.env.CHUTES_API_KEY || '',
        requesty: process.env.REQUESTY_API_KEY || ''
    };
}
// –ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
function estimateTokens(messages) {
    const text = messages.map(m => m.content).join(' ');
    return Math.ceil(text.length / 4); // –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: ~4 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ —Ç–æ–∫–µ–Ω
}
// –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–µ—Ä–∞
app.get('/health', (_req, res) => {
    const healthResponse = {
        status: 'ok',
        timestamp: new Date().toISOString(),
        uptime: process.uptime() * 1000, // Convert to milliseconds
        memory: {
            used: process.memoryUsage().heapUsed,
            total: process.memoryUsage().heapTotal,
            percentage: (process.memoryUsage().heapUsed / process.memoryUsage().heapTotal) * 100
        }
    };
    res.json(healthResponse);
});
// –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
app.get('/v1/models', (_req, res) => {
    const models = [];
    for (const [provider, providerModels] of Object.entries(llm_rotation_1.LlmManager.modelConfigurations)) {
        for (const model of providerModels) {
            models.push({
                id: model.id,
                object: 'model',
                created: Math.floor(Date.now() / 1000),
                owned_by: provider,
                permission: [],
                root: model.id,
                parent: null
            });
        }
    }
    const response = {
        object: 'list',
        data: models
    };
    res.json(response);
});
// –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
app.listen(port, () => {
    console.log(`üöÄ LLM Rotation Server –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É ${port}`);
    console.log(`üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã:`);
    console.log(`   POST /v1/chat/completions - –û—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è —á–∞—Ç–∞`);
    console.log(`   GET  /v1/models - –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π`);
    console.log(`   GET  /health - –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–∞`);
    console.log(`\nüîë –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è API –∫–ª—é—á–µ–π:`);
    console.log(`   GEMINI_API_KEY, OPENROUTER_API_KEY, HUGGINGFACE_API_KEY, –∏ —Ç.–¥.`);
});
exports.default = app;
//# sourceMappingURL=server.js.map